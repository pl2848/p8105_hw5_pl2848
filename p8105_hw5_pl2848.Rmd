---
title: "p8105_hw5_pl2848"
author: "Pei Liu"
date: "2022-11-10"
output: github_document
---

```{r, include = FALSE,message=FALSE,warning=FALSE}
library(tidyverse)
library(leaflet)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_grey() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
set.seed(1)
```


## Problem 1

The code chunk below imports the data in individual spreadsheets contained in `./data/zip_data/`. To do this, I create a dataframe that includes the list of all files in that directory and the complete path to each file. As a next step, I `map` over paths and import data using the `read_csv` function. Finally, I `unnest` the result of `map`.

```{r}
full_df = 
  tibble(
    files = list.files("data"),
    path = str_c("data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(data)
full_df
```

The result of the previous code chunk isn't tidy -- data are wide rather than long, and some important variables are included as parts of others. The code chunk below tides the data using string manipulations on the file, converting from wide to long, and selecting relevant variables. 

```{r}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)

tidy_df
```

Finally, the code chunk below creates a plot showing individual data, faceted by group. 

```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

This plot suggests high within-subject correlation -- subjects who start above average end up above average, and those that start below average end up below average. Subjects in the control group generally don't change over time, but those in the experiment group increase their outcome in a roughly linear way. 




## Problem 2
Describe the raw data. 

- There are 52179 observations and 12 variables in the raw data. Key variables includes:
uid, reported_data, victim_last, victim_first, victim_race, victim_age,victim_sex, city, state, lat, lon and disposition. Disposition records the status of homicide cases. 
```{r}
# read the file and add new column city_state
homicide = read_csv("data-homicides-master/homicide-data.csv") 
homicide
```

Create a city_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).
```{r}
# a function to determine whether the case was solved or not
solved_or_not = function(x){
  if(x == "Closed by arrest") {"solved"}
  else "unsolved"
}

# Added a new column to see if the case was solved or unsolved
homicide_by_city = homicide %>% 
  mutate(city_state = paste(city, state, sep =", "),
         status = as.character(map(disposition, solved_or_not))) %>% 
  group_by(status, city_state) %>% 
  summarise(number_of_homicides = n()) %>% 
  pivot_wider(names_from = status,
              values_from = number_of_homicides) 
  


homicide_by_city_total = homicide %>% 
  mutate(city_state = paste(city, state, sep =", "),
         status = as.character(map(disposition, solved_or_not))) %>% 
  group_by(city_state) %>% 
  summarise(number_of_homicides = n()) 
  
homicide_df = full_join(homicide_by_city,homicide_by_city_total)  %>% 
  drop_na()

homicide_df %>% 
  knitr::kable()
```

save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.
```{r}
BMD_unsolved_test = prop.test(1825, 2827, p = NULL,alternative = "two.sided",conf.level = 0.95, correct = TRUE) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)

BMD_unsolved_test
```

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each.
```{r}

city_prop_test = function(x,y){
  test_data = prop.test(x, y, p = NULL,conf.level = 0.95, correct = TRUE) %>%
    broom::tidy()
}

homicide_prop_test = 
tibble(
  city_state = homicide_df$city_state,
  test_result = purrr::map2(homicide_df$unsolved,homicide_df$number_of_homicides, city_prop_test)) %>% 
  unnest(cols = c(test_result)) %>% 
  select(c(city_state, estimate, conf.low, conf.high))

homicide_prop_test %>% 
  knitr::kable()

```

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.
```{r}
homicide_prop_test %>% 
  mutate(city_state = forcats::fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate))+ 
  geom_point(alpha = .5) +
  geom_boxplot() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.8) +
  labs(
    title = "Estimated Unsolved Homiside Cases Proportion by City State",
    x = "City, State",
    y = "Estimated Proportion with 95% CI",
  ) +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 
```


## Problem 3
Set mu=0. Generate 5000 datasets from the model x ~Normal(mu, sigma). 

For each dataset, save estimated mean and the p-value arising from a test of H: mu=0 using a=0.05.
```{r}
simulations = function( z, n=30, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n , mean = z , sd = sigma),
  )
  
    t.test(sim_data, alternative = "two.sided",mu = 0, conf.level = 0.95) %>%
    broom::tidy() %>%
    select(estimate,p.value)
}


sim_0 = 
  expand_grid(
    mean = 0,
    iter = 1:5000
  ) %>% 
  mutate(
    estimate_df = purrr::map(mean, simulations)
  ) %>% 
  unnest(estimate_df)

```


Repeat the above for μ={1,2,3,4,5,6}, and complete the following:
```{r}
sim_results_df = 
  expand_grid(
    mean = c(1,2,3,4,5,6),
    iter = 1:5000
  ) %>% 
  mutate(
    estimate_df = purrr::map(mean, simulations)
  ) %>% 
  unnest(estimate_df)


```


Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.
- When the effect size increases, the power of the test increases, given a fixed a. 
- The slope first increse steadly and then increase slowly until nearly zero.
```{r}
null_rej_plot = sim_results_df %>% 
  group_by(mean) %>% 
  summarise(rej_prop = sum(p.value < 0.05 )/5000) %>% 
  ggplot(aes(x = mean, y = rej_prop)) +
  geom_point() +
  labs(
    title = "The power of the test vs the true value of mu",
    x = "True mean (effect size)",
    y = "The proportion of times the null was rejected (the power of the test)",
  ) +
  geom_line()
  
  
  
ggsave("Null rejection proportion.png", null_rej_plot, width = 8, height = 5) 
null_rej_plot
```

Make a plot showing the average estimate of meanon the y axis and the true value of mu on the x axis. Make a second plot (or overlay on the first) the average estimate of means  only in samples for which the null was rejected on the y axis and the true value of mu on the x axis. Is the sample average of means across tests for which the null is rejected approximately equal to the true value of mu? Why or why not?

- The sample average of means for true mean = 4, 5, 6 for which the null is rejected approximately equal to the true value of mu, while the sample average for true mean = 1, 2, 3 were more deviated from the true mean.
- I think this is related to the power of the test. As the effect size increases, the power of the test increases. The power of test is increases and is close to 1 when the effect size is equal and larger than 4, so the average estimated means would be more and more closer to the true mean as the effect size increases.
```{r}
library(patchwork)

mean_esti_plot = sim_results_df %>% 
  group_by(mean) %>% 
  summarise(mean_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mean, y = mean_estimate)) +
  geom_point() +
  labs(
    title = "The estimated means (all) vs the true means",
    x = "True mean",
    y = "The Estimated Means (all)",
  ) +
  geom_smooth()
  
mean_esti_null_plot  = sim_results_df %>% 
  filter(p.value < 0.05) %>% 
  group_by(mean) %>% 
  summarise(mean_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mean, y = mean_estimate)) +
  geom_point() +
  labs(
    title = "The estimated means (for data that reject null) vs the true means",
    x = "True mean",
    y = "The Estimated Means (reject null)",
  ) +
  geom_smooth()
  


plot_mean = mean_esti_plot + mean_esti_null_plot
plot_mean
ggsave("estimated mean vs mu plot.png", plot_mean, width = 8, height = 5) 
```


